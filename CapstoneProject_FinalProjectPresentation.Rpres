Capstone ProjectFinal Project Presentation
========================================================
author: GaryFH
date: 10/27/2017
autosize: true

#First Slide
#========================================================


Introduction

========================================================

<small>

- The purpose of this application is to allow a user to input a phrase and it would predict the next word that they “most likely” want to type.

_ The n-grams that support the application come from blogs,  twits and news.


- One possible use could be for texting



- Milestone Report Link : [Milestone Report](https://rpubs.com/GaryFH/320044)



- Application link : [Shiny App - Next Word Prediction](https://ritheshkumar95.shinyapps.io/NextWordPrediction)



- Github Link : [Codes](https://github.com/ritheshkumar95/Capstone-Project)



</small>



Text Prediction Algorithm

========================================================

<small>



1. Preprocessing the text (e.g. filter non-English words, symbols)

2. Tokenization

3. Prepare unigram, bigram and trigram from the data

4. Count the occurrences of each unique unigram, bigram, trigram and quadgram

5. Calculate probabilties for each N-Gram using **Maximum Likelihood Estimate** And **Simlple Linear Interpolation**

6. Get the text phrase from the user

7. Extract the last three tokens (e.g. prev1, prev2) from the phrase. If the phrase is not long enough, extract the last two tokens or last token.

8. Return the top 3 matches with high proabability.

</small>



Shiny App - Next Word Prediction

========================================================

- Screenshot Of The App

```{r,echo=FALSE,fig.width=10,fig.height=4}

library(png)

library(grid)

img <- readPNG("img.png")

grid.raster(img)

```

- Instructions

     - Wait 10 seconds for the app to load

     - Enter text in input textbox

     - Top 3 most probable next words are displayed in the output textbox

</small></small>



Conclusion

========================================================

<small>

**Limitations**

 - RAM built-in to the laptop wasn't enough to handle the sheer size of the data

 - A sample representative population of ~1% was only used to train the model

 - Sparse values were removed during term document creation

 - The prediction model is biased towards train data. New word prediction is not very accurate



**References**

- [NLP Coursera Notes](http://files.asimihsan.com/courses/nlp-coursera-2013/notes/nlp.html#linear-interpolation-part-1)

- [Text Mining Infrastructure in R](http://www.jstatsoft.org/v25/i05/paper)

- [RWeka Package](http://cran.r-project.org/web/packages/RWeka/index.html)













For more details on authoring R presentations please visit <https://support.rstudio.com/hc/en-us/articles/200486468>.

- Bullet 1
- Bullet 2
- Bullet 3

Slide With Code
========================================================

```{r}
summary(cars)
```

Slide With Plot
========================================================

```{r, echo=FALSE}
plot(cars)
```
